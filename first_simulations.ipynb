{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13/05/2024: First Simulations \n",
    "\n",
    "Serves the purpose to understand the problem of fairness under distribution shifts closer and to observe what happens when different (fair) models get transferred to different environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import of all neccesary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import graphviz as gr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "#from scipy.stats import bernoulli\n",
    "random_seed = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a dataset/ import a real world dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Synthetic data\n",
    "\n",
    "We generate synthetic data according to the standard fairness model (SFM) introduced by Plecko and Bareinboim (2024).\n",
    "We will construct two SCMs:\n",
    "- 1: There is no direct effect (edge) from protected attribute X to outcome Y\n",
    "- 2: There is a direct effect (edge) from protected attribute X to outcome Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SCM1: no direct effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of positive outcomes for each group:\n",
      "X\n",
      "0    0.390219\n",
      "1    0.535292\n",
      "Name: Y, dtype: float64\n",
      "\n",
      "\n",
      "Proportion of X=0 and X=1:\n",
      "X\n",
      "1    0.5072\n",
      "0    0.4928\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "The total variation of Y with respect to the binary protected attribute X:\n",
      "0.14507264226309963\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "# Generate synthetic data according to the Standard-Fairness-Model (SFM) introduced by Plecko and Bareinboim (2024)\n",
    "n=10000\n",
    "\n",
    "#Define SCM generating function\n",
    "def SCM(n, direct_effect, mediator_effect, effect_X_W, spurious_effect):\n",
    "    # U -> exogenous variable drawn from N(0,1)\n",
    "    U = np.random.normal(0,1.5, size=(n,1))\n",
    "    # X -> {0,1}, representing protected attribute\n",
    "    X = np.random.binomial(n=1,p=(np.exp(U)/(1+np.exp(U))), size=(n,1))\n",
    "    # Z -> {0,1}, representing spurious attribute\n",
    "    Z = np.random.binomial(n=1,p=(np.exp(U)/(1+np.exp(U))), size=(n,1))\n",
    "    # W ->  {0,1}, representing mediating attribute\n",
    "    prob_W = 0.5 + effect_X_W*X\n",
    "    W = np.random.binomial(n=1,p=prob_W, size=(n,1))\n",
    "    # Y -> {0,1}, representing binary outcome\n",
    "    prob_Y = 0.1 + direct_effect*X + mediator_effect*W + spurious_effect*Z\n",
    "    Y = np.random.binomial(n=1,p=prob_Y, size=(n,1))\n",
    "    # Generate the data matrix\n",
    "    synthetic_data = np.column_stack((X,W,Z,Y))\n",
    "    synthetic_data_df = pd.DataFrame(synthetic_data, columns = [\"X\", \"W\",\"Z\", \"Y\"])\n",
    "    return synthetic_data_df\n",
    "\n",
    "\n",
    "#Generate synthetic data according to SCM1:\n",
    "SCM_no_direct_effect  = SCM(n, direct_effect=0, mediator_effect=0.25, effect_X_W=0.1, spurious_effect=0.45)\n",
    "\n",
    "#Display proportion of positive outcomes for each group\n",
    "print(\"Proportion of positive outcomes for each group:\")\n",
    "print(SCM_no_direct_effect.groupby(\"X\")[\"Y\"].mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "#Display proportion of values of X\n",
    "print(\"Proportion of X=0 and X=1:\")\n",
    "print(SCM_no_direct_effect[\"X\"].value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"The total variation of Y with respect to the binary protected attribute X:\")\n",
    "print(SCM_no_direct_effect.groupby(\"X\")[\"Y\"].mean().diff().iloc[-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding directed acyclic graph (DAG) according to SCM1 can be described as follows, where U is the unobserved exogenous variable confounding X and Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_DAG = gr.Digraph()   \n",
    "synthetic_data_DAG.edge(\"X\", \"W\")\n",
    "synthetic_data_DAG.edge(\"W\", \"Y\")\n",
    "synthetic_data_DAG.edge(\"Z\", \"Y\")\n",
    "synthetic_data_DAG.edge(\"U\", \"Z\", style=\"dotted\")  \n",
    "synthetic_data_DAG.edge(\"U\", \"X\", style=\"dotted\") \n",
    "synthetic_data_DAG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SCM2:  direct effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of positive outcomes for each group:\n",
      "X\n",
      "0    0.347606\n",
      "1    0.569795\n",
      "Name: Y, dtype: float64\n",
      "\n",
      "\n",
      "Proportion of X=0 and X=1:\n",
      "X\n",
      "1    0.5072\n",
      "0    0.4928\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "The total variation of Y with respect to the binary protected attribute X:\n",
      "0.22218943320086854\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "# Generate synthetic data according to the Standard-Fairness-Model (SFM) introduced by Plecko and Bareinboim (2024)\n",
    "\n",
    "\n",
    "#Generate synthetic data according to SCM2:\n",
    "SCM_direct_effect  = SCM(n, direct_effect=0.1, mediator_effect=0.25, effect_X_W=0.1, spurious_effect=0.35)\n",
    "\n",
    "#Display proportion of positive outcomes for each group\n",
    "print(\"Proportion of positive outcomes for each group:\")\n",
    "print(SCM_direct_effect.groupby(\"X\")[\"Y\"].mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "#Display proportion of values of X\n",
    "print(\"Proportion of X=0 and X=1:\")\n",
    "print(SCM_direct_effect[\"X\"].value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"The total variation of Y with respect to the binary protected attribute X:\")\n",
    "print(SCM_direct_effect.groupby(\"X\")[\"Y\"].mean().diff().iloc[-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding DAG according to SCM2 can be described as follows, where U is the unobserved exogenous variable confounding X and Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_DAG = gr.Digraph()   \n",
    "synthetic_data_DAG.edge(\"X\", \"W\")\n",
    "synthetic_data_DAG.edge(\"X\", \"Y\")\n",
    "synthetic_data_DAG.edge(\"W\", \"Y\")\n",
    "synthetic_data_DAG.edge(\"Z\", \"Y\")\n",
    "synthetic_data_DAG.edge(\"U\", \"Z\", style=\"dotted\")  \n",
    "synthetic_data_DAG.edge(\"U\", \"X\", style=\"dotted\") \n",
    "synthetic_data_DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Fit models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Unconstrained model \n",
    "#### 2.1.1 XGBoost\n",
    "\n",
    "We will be using XGBoost as our classifier as it is a widely used algorithm excelling at tabular data and therefore also being used a lot in real-life applications, which might inherit some fairness violations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.1 Fitting unconstrained model with data from SCM 1 - no direct effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=2, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=10, ...)\n",
      "\n",
      "\n",
      "Accuracy: 73.97%\n",
      "\n",
      "\n",
      "Total Variation/Demographic Parity of the unconstrained classifier:  0.2933\n"
     ]
    }
   ],
   "source": [
    "#one-hot encode the features X, W, Z and store as integer matrix\n",
    "X_encoded = pd.get_dummies(SCM_no_direct_effect[\"X\"], prefix=\"X\")\n",
    "W_encoded = pd.get_dummies(SCM_no_direct_effect[\"W\"], prefix=\"W\")\n",
    "Z_encoded = pd.get_dummies(SCM_no_direct_effect[\"Z\"], prefix=\"Z\")\n",
    "features_df = pd.concat([X_encoded, W_encoded, Z_encoded], axis=1)\n",
    "features_df = features_df.astype(int) \n",
    "\n",
    "#add the target variable Y to get the final dataset to be passed to classifier\n",
    "scm1_dataset = pd.concat([features_df, SCM_no_direct_effect[\"Y\"]], axis=1)\n",
    "\n",
    "\n",
    "#split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scm1_dataset.drop(\"Y\", axis=1), scm1_dataset[\"Y\"], test_size=0.33, random_state=random_seed)\n",
    "\n",
    "\n",
    "#fit the XGBoost classifier\n",
    "xgb = XGBClassifier(n_estimators=2, max_depth=3, learning_rate=1, objective='binary:logistic', random_state=random_seed)\n",
    "unconstrained_model_SCM1 = xgb.fit(X_train, y_train)\n",
    "#obtrain predictions from unconstrained model\n",
    "y_pred = unconstrained_model_SCM1.predict(X_test)\n",
    "\n",
    "#display model specification\n",
    "print(unconstrained_model_SCM1)\n",
    "print(\"\\n\")\n",
    "\n",
    "#display accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#display total variation between predicted outcomes being positive for each group (equivalent to demographic parity with respect to predicted outcomes)\n",
    "X_test_row_indices = X_test.index\n",
    "features_and_predictions = SCM_no_direct_effect.iloc[X_test_row_indices].drop(\"Y\",axis=1)\n",
    "features_and_predictions[\"Predictions\"] = y_pred\n",
    "total_variation_unsconstrained = (features_and_predictions.groupby(\"X\")[\"Predictions\"].mean().diff().iloc[-1].round(4))\n",
    "print(\"Total Variation/Demographic Parity of the unconstrained classifier: \", total_variation_unsconstrained )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: COMMENT ON RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.2 Fitting unconstrained model with data from SCM 2 - direct effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=2, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=10, ...)\n",
      "\n",
      "\n",
      "Accuracy: 71.21%\n",
      "\n",
      "\n",
      "Total Variation/Demographic Parity of the unconstrained classifier:  0.4773\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#one-hot encode the features X, W, Z and store as integer matrix\n",
    "X_encoded = pd.get_dummies(SCM_direct_effect[\"X\"], prefix=\"X\")\n",
    "W_encoded = pd.get_dummies(SCM_direct_effect[\"W\"], prefix=\"W\")\n",
    "Z_encoded = pd.get_dummies(SCM_direct_effect[\"Z\"], prefix=\"Z\")\n",
    "features_df = pd.concat([X_encoded, W_encoded, Z_encoded], axis=1)\n",
    "features_df = features_df.astype(int) \n",
    "\n",
    "#add the target variable Y to get the final dataset to be passed to classifier\n",
    "scm2_dataset = pd.concat([features_df, SCM_direct_effect[\"Y\"]], axis=1)\n",
    "\n",
    "\n",
    "#split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scm2_dataset.drop(\"Y\", axis=1), scm2_dataset[\"Y\"], test_size=0.33, random_state=random_seed)\n",
    "\n",
    "\n",
    "#fit the XGBoost classifier\n",
    "xgb = XGBClassifier(n_estimators=2, max_depth=3, learning_rate=1, objective='binary:logistic', random_state=random_seed)\n",
    "unconstrained_model_SCM2 = xgb.fit(X_train, y_train)\n",
    "#obtrain predictions from unconstrained model\n",
    "y_pred = unconstrained_model_SCM2.predict(X_test)\n",
    "\n",
    "#display model specification\n",
    "print(unconstrained_model_SCM2)\n",
    "print(\"\\n\")\n",
    "\n",
    "#display accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#display total variation between predicted outcomes being positive for each group (equivalent to demographic parity with respect to predicted outcomes)\n",
    "X_test_row_indices = X_test.index\n",
    "features_and_predictions = SCM_direct_effect.iloc[X_test_row_indices].drop(\"Y\",axis=1)\n",
    "features_and_predictions[\"Predictions\"] = y_pred\n",
    "total_variation_unsconstrained = (features_and_predictions.groupby(\"X\")[\"Predictions\"].mean().diff().iloc[-1].round(4))\n",
    "print(\"Total Variation/Demographic Parity of the unconstrained classifier: \", total_variation_unsconstrained )\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: COMMENT ON RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model with fairness constraint\n",
    "#### 2.1.1 XGBoost + Demographic Parity\n",
    "\n",
    "We will be using XGBoost as our classifier as it is a widely used algorithm excelling at tabular data and therefore also being used a lot in real-life applications, which might inherit some fairness violations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
